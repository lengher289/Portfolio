{"cells":[{"cell_type":"markdown","metadata":{"id":"YGc8SOEWPmKW"},"source":["# Lab 2"]},{"cell_type":"code","execution_count":334,"metadata":{"id":"HKH76_F0OE2J","executionInfo":{"status":"ok","timestamp":1675548128406,"user_tz":360,"elapsed":219,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["FIRST_NAME = \"Leng\"\n","LAST_NAME = \"Her\"\n","STUDENT_ID = \"5445877\""]},{"cell_type":"markdown","metadata":{"id":"s7F2plBRGiLv"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"X-xqTZ6XGrLy"},"source":["Scikit Learn is one of the most prominent tools for building machine learning models in the data science industry. It contains a plethora of standardized tools for managing the entire machine learning development workflow.\n","\n","In this lab, you will use the same simulated data set as last week to build, validate, and evaluate machine learning models with various regression algorithms. We will also save this model to a file so it can be utilized to make future predictions."]},{"cell_type":"markdown","metadata":{"id":"AxYIVgMbJvkC"},"source":["## The Data Set"]},{"cell_type":"markdown","metadata":{"id":"ws58RVK7Ro24"},"source":["**Data Description**"]},{"cell_type":"markdown","metadata":{"id":"pfqoS4rLRtHS"},"source":["This is a simulated data set of students performance in the INET 4062 class. _None of these are actual students._"]},{"cell_type":"markdown","metadata":{"id":"PgN86a7UPAWN"},"source":["**Data Dictionary**"]},{"cell_type":"markdown","metadata":{"id":"XMOix-dVPAGl"},"source":["| Column Name | Type | Description |\n","| :----------- | :-- | :----------- |\n","| studentId | `int` | Unique Id of student |\n","| gpa | `float` | Current cumulative GPA |\n","| labHours | `float` | Number of hours spent per week on labs |\n","| studyHours | `float` | Number of hours spent studying for each exam |\n","| took4061 | `int` | Binary if student took INET 4061 (0=No, 1=Yes) |\n","| pythonExp | `int` | A High, Medium, or Low rating from student on previous python experience (0=Low, 1=Medium, 2=High) |\n","| statsRating | `int` | A 0-5 rating of ability on statistics |\n","| height | `float` | Height of student in inches |\n","| eyeColor | `str` | Eye color of student |\n","| followers | `int` | Number of followers on all social media accounts |\n","| grade | `float` | Percentage grade in INET 4062 out of 100 |\n","| letterGrade | `str` | Letter grade derived from the percentage |\n"]},{"cell_type":"markdown","metadata":{"id":"kKYZsnTqKOE6"},"source":["**Data Sample**"]},{"cell_type":"markdown","metadata":{"id":"PUgfSBcPO-dF"},"source":["|   studentId |     gpa |   labHours |   studyHours |   took4061 |   pythonExp |   statsRating |   height | eyeColor   |   followers |   grade | letterGrade   |\n","|------------:|--------:|-----------:|-------------:|-----------:|------------:|--------------:|---------:|:-----------|------------:|--------:|:--------------|\n","|           0 | 3.62061 |   3.0089   |     4.36066  |          1 |           2 |             3 |  69.4933 | brown      |         632 |   92.31 | A-            |\n","|           1 | 3.19391 |   2.524    |     4.88687  |          0 |           2 |             2 |  67.3275 | blue       |          44 |   85.59 | B             |\n","|           2 | 3.19453 |   0.903686 |     2.0478   |          1 |           1 |             5 |  69.3401 | green      |         181 |   88.39 | B+            |\n","|           3 | 3.27793 |   4.88015  |     0.822806 |          1 |           2 |             4 |  67.8951 | blue       |         347 |   90.91 | A-            |\n","|           4 | 2.5     |   1.47281  |     7.51036  |          0 |           2 |             4 |  67.708  | brown      |        1070 |   84.14 | B             |\n","|           5 | 2.56162 |   4.53166  |     5.50934  |          0 |           1 |             5 |  69.6897 | hazel      |          18 |   84.37 | B             |\n","|           6 | 3.15581 |   2.60646  |     1.56167  |          0 |           1 |             5 |  69.045  | hazel      |        7007 |   84.2  | B             |\n","|           7 | 3.73405 |   2.41052  |     2.99812  |          1 |           2 |             5 |  66.5794 | brown      |        5599 |   93.6  | A             |\n","|           8 | 2.98454 |   2.68131  |     1.73898  |          1 |           2 |             4 |  69.1432 | hazel      |        1206 |   88.73 | B+            |\n","|           9 | 3.84509 |   5.43147  |     4.9316   |          1 |           1 |             1 |  68.034  | blue       |       40097 |   92.12 | A-            |"]},{"cell_type":"code","execution_count":335,"metadata":{"id":"6ep-lE3SK4sv","executionInfo":{"status":"ok","timestamp":1675548128613,"user_tz":360,"elapsed":8,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","n = 1000 # number of records to simulate\n","np.random.seed(40) # set the seed of the random number generator\n","\n","# Current GPA\n","gpa = 0.4 * np.random.randn(n) + 3.25\n","gpa = np.clip(gpa, 2.5, 4.0)\n","\n","# Average hours per week on Labs\n","labHours = 5.5/np.exp(2*np.random.rand(n))\n","\n","# Number of hours studying for exam\n","studyHours = np.power(2*np.random.rand(n) + 0.75, 2)\n","\n","# Junior or Senior\n","isSenior = np.random.binomial(size=n, n=1, p=0.67)\n","\n","# Took 4061\n","took4061 = np.random.binomial(size=n, n=1, p=0.75)\n","\n","# Previous Python Experience\n","pythonExp = np.random.binomial(size=n, n=2, p=0.70)\n","\n","# Ability in statistics\n","statsRating = np.random.binomial(size=n, n=5, p=0.75)\n","\n","# Height\n","height = 4 * np.random.rand(n) + 66.5\n","\n","# Eye Color\n","eyeColor = np.random.choice([\"blue\", \"green\", \"brown\", \"hazel\"], n)\n","\n","# Social media followers\n","followers = (10 ** (1+5*np.random.beta(3, 7, size=n))).round()\n","\n","# simulate grades\n","grade = 72 + (((gpa**2)/3 + np.sqrt(statsRating+1)) * \n","              np.sqrt(labHours/3 + studyHours/6 + pythonExp + 3*took4061)) + \\\n","              (1+3*np.random.rand())\n","\n","# Compile columns into a DataFrame\n","students_df = pd.DataFrame({\n","    'gpa' : gpa,\n","    'labHours' : labHours,\n","    'studyHours' : studyHours,\n","    'took4061' : took4061,\n","    'pythonExp' : pythonExp,\n","    'statsRating' : statsRating,\n","    'height' : height,\n","    'eyeColor' : eyeColor,\n","    'followers' : followers,\n","    'grade' : grade.round(2)\n","})\n","\n","# Define a function to calculate the letter grade based\n","# on the percentage in the class\n","def getLetterGrade(x):\n","  if x < 76.67:\n","    return(\"C\")\n","  elif x < 80:\n","    return(\"C+\")\n","  elif x < 83.33:\n","    return(\"B-\")\n","  elif x < 86.67:\n","    return(\"B\")\n","  elif x < 90:\n","    return(\"B+\")\n","  elif x < 93.33:\n","    return(\"A-\")\n","  else:\n","    return(\"A\")\n","\n","# Add the letter grade column to the DataFrame\n","students_df['letterGrade'] = students_df['grade'].apply(lambda row: getLetterGrade(row))\n","\n","# Rename the index of the DataFrame to be `studentId`\n","# because that index uniquely identifies 1 student\n","students_df.index.rename(\"studentId\", inplace=True)\n","students_df.reset_index(drop=False, inplace=True)"]},{"cell_type":"code","execution_count":336,"metadata":{"id":"vyc_uYJ3L6Vm","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1675548128613,"user_tz":360,"elapsed":7,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"87ba4337-df6e-418c-8f92-5fde8cf6da5e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["     studentId       gpa  labHours  studyHours  took4061  pythonExp  \\\n","0            0  3.006981  3.013592    3.187031         1          1   \n","1            1  3.199545  1.025472    2.750329         1          0   \n","2            2  2.976157  3.032981    7.211016         1          2   \n","3            3  3.621486  1.799475    5.882726         1          2   \n","4            4  2.512240  3.950051    3.418261         1          2   \n","..         ...       ...       ...         ...       ...        ...   \n","995        995  2.801776  2.742993    2.137272         1          2   \n","996        996  3.618104  1.017808    4.031764         1          0   \n","997        997  3.838771  1.576157    3.818294         0          2   \n","998        998  3.688545  1.297447    0.953019         1          1   \n","999        999  3.157349  2.109959    3.289108         1          2   \n","\n","     statsRating     height eyeColor  followers  grade letterGrade  \n","0              2  66.605363     blue      154.0  85.57           B  \n","1              3  68.511122    hazel     1091.0  84.96           B  \n","2              4  68.770468    brown      749.0  88.34          B+  \n","3              4  67.058603    brown      136.0  91.36          A-  \n","4              3  69.320191    brown      802.0  85.17           B  \n","..           ...        ...      ...        ...    ...         ...  \n","995            4  68.828923     blue     3712.0  86.56           B  \n","996            4  69.533289     blue     5676.0  87.62          B+  \n","997            3  69.373830    green      104.0  86.70          B+  \n","998            3  68.642846     blue      262.0  88.41          B+  \n","999            4  68.545741    hazel       52.0  88.30          B+  \n","\n","[1000 rows x 12 columns]"],"text/html":["\n","  <div id=\"df-fc990bc7-e0b0-4687-867a-048919880dda\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>studentId</th>\n","      <th>gpa</th>\n","      <th>labHours</th>\n","      <th>studyHours</th>\n","      <th>took4061</th>\n","      <th>pythonExp</th>\n","      <th>statsRating</th>\n","      <th>height</th>\n","      <th>eyeColor</th>\n","      <th>followers</th>\n","      <th>grade</th>\n","      <th>letterGrade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3.006981</td>\n","      <td>3.013592</td>\n","      <td>3.187031</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>66.605363</td>\n","      <td>blue</td>\n","      <td>154.0</td>\n","      <td>85.57</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>3.199545</td>\n","      <td>1.025472</td>\n","      <td>2.750329</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>68.511122</td>\n","      <td>hazel</td>\n","      <td>1091.0</td>\n","      <td>84.96</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2.976157</td>\n","      <td>3.032981</td>\n","      <td>7.211016</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>68.770468</td>\n","      <td>brown</td>\n","      <td>749.0</td>\n","      <td>88.34</td>\n","      <td>B+</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3.621486</td>\n","      <td>1.799475</td>\n","      <td>5.882726</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>67.058603</td>\n","      <td>brown</td>\n","      <td>136.0</td>\n","      <td>91.36</td>\n","      <td>A-</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2.512240</td>\n","      <td>3.950051</td>\n","      <td>3.418261</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>69.320191</td>\n","      <td>brown</td>\n","      <td>802.0</td>\n","      <td>85.17</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>995</td>\n","      <td>2.801776</td>\n","      <td>2.742993</td>\n","      <td>2.137272</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>68.828923</td>\n","      <td>blue</td>\n","      <td>3712.0</td>\n","      <td>86.56</td>\n","      <td>B</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>996</td>\n","      <td>3.618104</td>\n","      <td>1.017808</td>\n","      <td>4.031764</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>69.533289</td>\n","      <td>blue</td>\n","      <td>5676.0</td>\n","      <td>87.62</td>\n","      <td>B+</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>997</td>\n","      <td>3.838771</td>\n","      <td>1.576157</td>\n","      <td>3.818294</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>69.373830</td>\n","      <td>green</td>\n","      <td>104.0</td>\n","      <td>86.70</td>\n","      <td>B+</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>998</td>\n","      <td>3.688545</td>\n","      <td>1.297447</td>\n","      <td>0.953019</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>68.642846</td>\n","      <td>blue</td>\n","      <td>262.0</td>\n","      <td>88.41</td>\n","      <td>B+</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>999</td>\n","      <td>3.157349</td>\n","      <td>2.109959</td>\n","      <td>3.289108</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>68.545741</td>\n","      <td>hazel</td>\n","      <td>52.0</td>\n","      <td>88.30</td>\n","      <td>B+</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 12 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc990bc7-e0b0-4687-867a-048919880dda')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc990bc7-e0b0-4687-867a-048919880dda button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc990bc7-e0b0-4687-867a-048919880dda');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":336}],"source":["students_df"]},{"cell_type":"markdown","metadata":{"id":"NfJL3-aJGc3S"},"source":["## Question 1\n","\n","The first step is to split data into the independent variables (features) and the dependent variable (label), and to split the data into a train and test set. \n","\n","First, create a DataFrame named `X` with only the following columns _\"gpa\", \"labHours\", \"studyHours\", \"took4061\", \"pythonExp\", \"statsRating\"._\n","\n","Next, create a Series (a 1 column DataFrame) name `y` that contains just the _\"grade\"_ column of the DataFrame.\n","\n","Then do a train/test split on the `X` and `y` datasets where 75% of the rows are in the train set, and 25% are in the test set. Set the random seed to `4062` for the train/test split.\n"]},{"cell_type":"markdown","metadata":{"id":"bgS3mBTnGcrl"},"source":["### Resources"]},{"cell_type":"markdown","metadata":{"id":"LFmDch87WNw7"},"source":["**Scikit Learn Documentation**\n"," * sklearn.model_selection.train_test_split ([link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n","\n","**Pandas Documentation**\n","* Indexing and Selecting data ([link](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html))\n","\n","**Examples**\n"," * Selecting multiple columns [datagy](https://datagy.io/pandas-select-columns/)\n"," * Selecting multiple columns [statology](https://www.statology.org/pandas-select-multiple-columns/)\n"," * Train Test Split ([Real Python](https://realpython.com/train-test-split-python-data/))\n"," * Train Test Split ([Machine Learning Mastery](https://machinelearningmastery.com/train-test-split-for-evaluating-machine-learning-algorithms/))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"B2L1VrLLB-KY"},"source":["### Answer"]},{"cell_type":"code","execution_count":337,"metadata":{"id":"4qQRjUxXIEpM","executionInfo":{"status":"ok","timestamp":1675548128613,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":338,"metadata":{"id":"Zc9fayE8DosG","executionInfo":{"status":"ok","timestamp":1675548128614,"user_tz":360,"elapsed":7,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["# select the independent variables and store in X\n","X = students_df[[\"gpa\", \"labHours\", \"studyHours\", \"took4061\", \"pythonExp\", \"statsRating\"]]\n","\n","# select the dependent variable (label) and store in y\n","y = students_df[\"grade\"]\n","\n","# split the data into a train and test set with 75% of the data in the train set and 25% in the test set\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=4062)"]},{"cell_type":"code","execution_count":338,"metadata":{"id":"yzOaEQT6HwIs","executionInfo":{"status":"ok","timestamp":1675548128614,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"JVK-x4o0RqIA"},"source":["## Question 2\n","\n","One hot encode the categorical features for the model _\"took4061\", \"pythonExp\", \"statsRating\"_. Fit and transform the OneHotEncoder on the `X_train` DataFrame. Save the results of the one hot encoding transformation into a variable named `categoricalVars`.\n","\n","Next, convert the `categoricalVars` array into a Pandas DataFrame named `categoricalVars_df` with the column names from the `.get_feature_names_out()` method of your OneHotEncoder object.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ypnQYkILcd6M"},"source":["### Resources"]},{"cell_type":"markdown","metadata":{"id":"ANZfEzI3cdtl"},"source":["**Scikit Learn Documentation**\n"," * sklearn.preprocessing.OneHotEncoder ([link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html))\n","\n","**Examples**\n"," * Datagy ([link](https://datagy.io/sklearn-one-hot-encode/))\n"," * Geeks4Geeks ([link](https://www.geeksforgeeks.org/ml-one-hot-encoding-of-datasets-in-python/))"]},{"cell_type":"markdown","metadata":{"id":"h7eiF1Slcf5T"},"source":["### Answer"]},{"cell_type":"code","execution_count":339,"metadata":{"id":"inf23mwAR8D5","executionInfo":{"status":"ok","timestamp":1675548128614,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["from sklearn.preprocessing import OneHotEncoder"]},{"cell_type":"code","execution_count":340,"metadata":{"id":"XVJNxQZgIHV0","executionInfo":{"status":"ok","timestamp":1675548128614,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["\n","encoder = OneHotEncoder()\n","categoricalVars = encoder.fit_transform(X_train[[\"took4061\", \"pythonExp\", \"statsRating\"]])\n","categoricalVars_df = pd.DataFrame(categoricalVars.toarray(), columns=encoder.get_feature_names_out())\n"]},{"cell_type":"markdown","metadata":{"id":"JnQfIeC9bMNG"},"source":["## Question 3\n","\n","Normalize the numeric features for the machine learning models _\"gpa\", \"labHours\", \"studyHours\"_.  Fit and transform the StandardScaler on the `X_train` DataFrame. Save the results of the transformation into a variable named `normalizedVars`. \n","\n","Next, convert the `normalizedVars` array into a Pandas DataFrame named `normalizedVars_df` with the column names from the `.get_feature_names_out()` method of your StandardScaler object."]},{"cell_type":"markdown","metadata":{"id":"bVkr-Vg9p4Qm"},"source":["### Resources"]},{"cell_type":"markdown","metadata":{"id":"Kj_VRxdZp4AQ"},"source":["**Scikit Learn Documentation**\n"," * sklearn.preprocessing.StandardScaler ([link](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html))\n","\n","**Examples**\n"," * Machine Learning Mastery ([link](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/))\n"," * BenAlexKeen ([link](https://benalexkeen.com/feature-scaling-with-scikit-learn/))"]},{"cell_type":"markdown","metadata":{"id":"U5XUYh5up3fa"},"source":["### Answer"]},{"cell_type":"code","execution_count":341,"metadata":{"id":"hIYvBwhzJaL1","executionInfo":{"status":"ok","timestamp":1675548128614,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":342,"metadata":{"id":"72ZWAG2cJZwx","executionInfo":{"status":"ok","timestamp":1675548128757,"user_tz":360,"elapsed":148,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["\n","\n","# Select the numeric features\n","numeric_features = [\"gpa\", \"labHours\", \"studyHours\"]\n","X_train_num = X_train[numeric_features]\n","\n","# Fit and transform the StandardScaler on the numeric features in X_train\n","scaler = StandardScaler()\n","normalizedVars = scaler.fit_transform(X_train_num)\n","\n","# Convert normalizedVars array into a Pandas DataFrame\n","normalizedVars_df = pd.DataFrame(normalizedVars, columns=numeric_features)\n"]},{"cell_type":"markdown","metadata":{"id":"VD5Z00PnvJJW"},"source":["## Question 4\n","\n","Combine the columns of the two DataFrames `categoricalVars_df` and `normalizedVars_df`. Use the `pd.concat()` function with `axis='columns'`. Save the resulting DataFrame into a variable named `X_train_cleaned`."]},{"cell_type":"markdown","metadata":{"id":"8FfwZNr3vMlS"},"source":["### Resources"]},{"cell_type":"markdown","metadata":{"id":"fJpqZypnvWmJ"},"source":["**Pandas Documentation**\n","* pd.concat ([link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html))\n","\n","**Examples**\n","* Statology ([link](https://www.statology.org/concatenate-two-pandas-dataframes/))\n","* W3Resource ([link](https://www.w3resource.com/pandas/concat.php))"]},{"cell_type":"markdown","metadata":{"id":"EFrUT7rsvWcW"},"source":["### Answer"]},{"cell_type":"code","execution_count":343,"metadata":{"id":"Es2gEMRHJZmZ","executionInfo":{"status":"ok","timestamp":1675548128757,"user_tz":360,"elapsed":148,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["X_train_cleaned = pd.concat([categoricalVars_df, normalizedVars_df], axis='columns')\n"]},{"cell_type":"code","source":["X_train_cleaned"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"fT6LunBQX8w8","executionInfo":{"status":"ok","timestamp":1675548128758,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"74e5b83b-1ef2-4c3f-b150-1ed5659f9473"},"execution_count":344,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     took4061_0  took4061_1  pythonExp_0  pythonExp_1  pythonExp_2  \\\n","0           0.0         1.0          0.0          0.0          1.0   \n","1           0.0         1.0          0.0          1.0          0.0   \n","2           1.0         0.0          1.0          0.0          0.0   \n","3           0.0         1.0          0.0          0.0          1.0   \n","4           0.0         1.0          0.0          0.0          1.0   \n","..          ...         ...          ...          ...          ...   \n","745         0.0         1.0          0.0          0.0          1.0   \n","746         0.0         1.0          0.0          1.0          0.0   \n","747         0.0         1.0          0.0          1.0          0.0   \n","748         1.0         0.0          0.0          0.0          1.0   \n","749         0.0         1.0          0.0          1.0          0.0   \n","\n","     statsRating_0  statsRating_1  statsRating_2  statsRating_3  \\\n","0              0.0            0.0            0.0            0.0   \n","1              0.0            1.0            0.0            0.0   \n","2              0.0            0.0            0.0            0.0   \n","3              0.0            0.0            0.0            1.0   \n","4              0.0            0.0            0.0            1.0   \n","..             ...            ...            ...            ...   \n","745            0.0            0.0            0.0            0.0   \n","746            0.0            0.0            0.0            1.0   \n","747            0.0            0.0            0.0            0.0   \n","748            0.0            0.0            0.0            0.0   \n","749            0.0            0.0            0.0            0.0   \n","\n","     statsRating_4  statsRating_5       gpa  labHours  studyHours  \n","0              1.0            0.0  0.455838 -0.704009   -0.676952  \n","1              0.0            0.0  0.812140 -0.939033   -0.352502  \n","2              0.0            1.0  0.155625  1.593085    1.425394  \n","3              0.0            0.0  1.294941 -0.740124   -0.039968  \n","4              0.0            0.0 -1.462300 -1.150700    0.052982  \n","..             ...            ...       ...       ...         ...  \n","745            1.0            0.0 -1.010872  0.527532   -0.844072  \n","746            0.0            0.0  1.936559  1.803265    1.516103  \n","747            0.0            1.0  0.694991 -1.129082    1.051331  \n","748            1.0            0.0  0.197053 -1.055185    0.639203  \n","749            1.0            0.0  1.082019 -0.961691    0.247238  \n","\n","[750 rows x 14 columns]"],"text/html":["\n","  <div id=\"df-8b930edb-7efe-4305-82a0-60db11c719a9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>took4061_0</th>\n","      <th>took4061_1</th>\n","      <th>pythonExp_0</th>\n","      <th>pythonExp_1</th>\n","      <th>pythonExp_2</th>\n","      <th>statsRating_0</th>\n","      <th>statsRating_1</th>\n","      <th>statsRating_2</th>\n","      <th>statsRating_3</th>\n","      <th>statsRating_4</th>\n","      <th>statsRating_5</th>\n","      <th>gpa</th>\n","      <th>labHours</th>\n","      <th>studyHours</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.455838</td>\n","      <td>-0.704009</td>\n","      <td>-0.676952</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.812140</td>\n","      <td>-0.939033</td>\n","      <td>-0.352502</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.155625</td>\n","      <td>1.593085</td>\n","      <td>1.425394</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.294941</td>\n","      <td>-0.740124</td>\n","      <td>-0.039968</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1.462300</td>\n","      <td>-1.150700</td>\n","      <td>0.052982</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>745</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>-1.010872</td>\n","      <td>0.527532</td>\n","      <td>-0.844072</td>\n","    </tr>\n","    <tr>\n","      <th>746</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.936559</td>\n","      <td>1.803265</td>\n","      <td>1.516103</td>\n","    </tr>\n","    <tr>\n","      <th>747</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.694991</td>\n","      <td>-1.129082</td>\n","      <td>1.051331</td>\n","    </tr>\n","    <tr>\n","      <th>748</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.197053</td>\n","      <td>-1.055185</td>\n","      <td>0.639203</td>\n","    </tr>\n","    <tr>\n","      <th>749</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.082019</td>\n","      <td>-0.961691</td>\n","      <td>0.247238</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>750 rows × 14 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b930edb-7efe-4305-82a0-60db11c719a9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8b930edb-7efe-4305-82a0-60db11c719a9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8b930edb-7efe-4305-82a0-60db11c719a9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":344}]},{"cell_type":"markdown","metadata":{"id":"uwRGo7WCy9vf"},"source":["## Question 5\n","\n","Test the performance of 3 different algorithms to predict the grades of each student: Support Vector Machines, K-Nearest Neighbors, and Random Forest. Try various different hyperparameters for each algorithm (_except for this case, do not use `weight=distance` for KNN_). \n","\n","Track the Mean Absolute Error (MAE) on the training data set for each set of hyperparameters for each algorithm that you try. "]},{"cell_type":"markdown","metadata":{"id":"AMMl7qKsBLJ3"},"source":["### Resources"]},{"cell_type":"markdown","metadata":{"id":"WaSdJDMwBPAc"},"source":["**Scikit Learn Documentation**\n","* LinearSVR ([link](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html))\n","* KNeighborsRegressor ([link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html))\n","* RandomForestRegressor ([link](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html))\n","* mean_absolute_error ([link](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error))\n"]},{"cell_type":"markdown","metadata":{"id":"Xe-JOwigBO1e"},"source":["### Answer"]},{"cell_type":"code","execution_count":345,"metadata":{"id":"0VjH2OyVJ7A2","executionInfo":{"status":"ok","timestamp":1675548128758,"user_tz":360,"elapsed":5,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["from sklearn.svm import LinearSVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"code","source":["svm = LinearSVR()\n","knn = KNeighborsRegressor()\n","rf = RandomForestRegressor()"],"metadata":{"id":"maNc08XylpsL","executionInfo":{"status":"ok","timestamp":1675548128758,"user_tz":360,"elapsed":5,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"execution_count":346,"outputs":[]},{"cell_type":"code","execution_count":347,"metadata":{"id":"BWYRbcJiNYxa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675548129111,"user_tz":360,"elapsed":357,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"f33e2b81-4e41-46e8-f6ba-69d2a13932e4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor()"]},"metadata":{},"execution_count":347}],"source":["# Fitting the models\n","svm.fit(X_train_cleaned, y_train)\n","knn.fit(X_train_cleaned, y_train)\n","rf.fit(X_train_cleaned, y_train)"]},{"cell_type":"code","execution_count":348,"metadata":{"id":"18zfnTLMNpdG","executionInfo":{"status":"ok","timestamp":1675548129111,"user_tz":360,"elapsed":3,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["# Predicting with the models\n","y_train_pred_svm = svm.predict(X_train_cleaned)\n","y_train_pred_knn = knn.predict(X_train_cleaned)\n","y_train_pred_rf = rf.predict(X_train_cleaned)"]},{"cell_type":"code","execution_count":349,"metadata":{"id":"zTwhNxTbaDDk","executionInfo":{"status":"ok","timestamp":1675548129112,"user_tz":360,"elapsed":4,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["# Calculating MAE\n","mae_svm = mean_absolute_error(y_train, y_train_pred_svm)\n","mae_knn = mean_absolute_error(y_train, y_train_pred_knn)\n","mae_rf = mean_absolute_error(y_train, y_train_pred_rf)"]},{"cell_type":"code","source":["print(\"Mean Absolute Error - SVM:\", mae_svm)\n","print(\"Mean Absolute Error - KNN:\", mae_knn)\n","print(\"Mean Absolute Error - RF:\", mae_rf)"],"metadata":{"id":"m7KP-Hjalq2Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675548129278,"user_tz":360,"elapsed":170,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"74f6afd8-c093-4d68-fa28-31c67bbf3493"},"execution_count":350,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Absolute Error - SVM: 0.2676725559973789\n","Mean Absolute Error - KNN: 0.48866133333333284\n","Mean Absolute Error - RF: 0.16256840000000358\n"]}]},{"cell_type":"markdown","metadata":{"id":"vMY5WHAaBqHn"},"source":["## Question 6\n","\n","Evaluate the results of the models on the training data set. Select the model with the lowest Mean Absolute Error (MAE). Then re-train that algorithm with the same hyperparameters and calculate the MAE on the test data set."]},{"cell_type":"code","source":["encoder = OneHotEncoder()\n","categoricalVars = encoder.fit_transform(X_train[[\"took4061\", \"pythonExp\", \"statsRating\"]])\n","categoricalVars_df = pd.DataFrame(categoricalVars.toarray(), columns=encoder.get_feature_names_out())\n"],"metadata":{"id":"Q6Id1tJ_bg-R","executionInfo":{"status":"ok","timestamp":1675548129278,"user_tz":360,"elapsed":3,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"execution_count":351,"outputs":[]},{"cell_type":"code","source":["#Apply encoding on the test set\n","\n","# Categorical feature preprocessing\n","categoricalVars = encoder.transform(X_test[[\"took4061\", \"pythonExp\", \"statsRating\"]])\n","categoricalVars_df = pd.DataFrame(categoricalVars.toarray(), columns=encoder.get_feature_names_out())\n","\n","# Numerical feature preprocessing\n","normalizedVars = scaler.transform(X_test[[\"gpa\", \"labHours\", \"studyHours\"]])\n","normalizedVars_df = pd.DataFrame(normalizedVars, columns=scaler.get_feature_names_out())\n","\n","# Combine all features\n","X_test_cleaned = pd.concat([categoricalVars_df, normalizedVars_df], axis='columns')"],"metadata":{"id":"tkB9L3VJbBgT","executionInfo":{"status":"ok","timestamp":1675548129278,"user_tz":360,"elapsed":2,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"execution_count":352,"outputs":[]},{"cell_type":"code","source":["# Re-train the selected model with the same hyperparameters\n","rf.fit(X_train_cleaned, y_train)\n","y_pred = rf.predict(X_test_cleaned)\n","best_model_mae = mean_absolute_error(y_test, y_pred)\n","print('MAE on the test data set:', best_model_mae)"],"metadata":{"id":"GjeFbf68f5Dx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675548129531,"user_tz":360,"elapsed":255,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"250be8ca-6509-4231-8e34-c17175c89386"},"execution_count":353,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE on the test data set: 0.4021979999999989\n"]}]},{"cell_type":"markdown","metadata":{"id":"f_Gjd2W9ED63"},"source":["## Question 7\n","\n","Save the model with the lowest mean absolute error (MAE) to a Pickle file named `model.pkl`. \n","* Retrain the algorithm with the same hyper parameters as in the previous step.\n","* Get the mean average error of the model on the test data set\n","* Use the Pickle Python package the model object to a file named `model.pkl`"]},{"cell_type":"markdown","metadata":{"id":"i4jEIdxPEDuH"},"source":["### Resources"]},{"cell_type":"markdown","metadata":{"id":"kupwkYGwEDeQ"},"source":["**Python Documentation**\n","* Pickle Examples ([link](https://docs.python.org/3/library/pickle.html#examples))\n","* Pickle Docs ([link](https://docs.python.org/3/library/pickle.html#))\n","\n","**Examples**\n","* Datacamp ([link](https://www.datacamp.com/tutorial/pickle-python-tutorial))\n","* Real Python ([link](https://realpython.com/python-pickle-module/))"]},{"cell_type":"markdown","metadata":{"id":"QMiV_zdDFz3n"},"source":["### Answer"]},{"cell_type":"code","execution_count":354,"metadata":{"id":"skN5vE15Fr5V","executionInfo":{"status":"ok","timestamp":1675548129789,"user_tz":360,"elapsed":260,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["import pickle"]},{"cell_type":"code","source":["rf.fit(X_train_cleaned, y_train)"],"metadata":{"id":"Tc5Szeng1iBG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675548129946,"user_tz":360,"elapsed":158,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"af02eedc-8b7f-41eb-d4f2-bcef6560b2a1"},"execution_count":355,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor()"]},"metadata":{},"execution_count":355}]},{"cell_type":"code","source":["y_pred2 = rf.predict(X_test_cleaned)"],"metadata":{"id":"ebaU_UTI1q_l","executionInfo":{"status":"ok","timestamp":1675548130195,"user_tz":360,"elapsed":250,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"execution_count":356,"outputs":[]},{"cell_type":"code","source":["best_model_mae2 = mean_absolute_error(y_test, y_pred)\n","print('MAE on the test data set:', best_model_mae2)"],"metadata":{"id":"9vI0-qV82IIs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675548130195,"user_tz":360,"elapsed":7,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"6e51cd4f-ede0-411f-a546-7c2aca7b2ab7"},"execution_count":357,"outputs":[{"output_type":"stream","name":"stdout","text":["MAE on the test data set: 0.4021979999999989\n"]}]},{"cell_type":"code","execution_count":358,"metadata":{"id":"wWD4A3q3NDM_","executionInfo":{"status":"ok","timestamp":1675548130195,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["with open(\"model.pkl\", \"wb\") as file:\n","    pickle.dump(rf, file)"]},{"cell_type":"markdown","metadata":{"id":"otioAyZoj3ro"},"source":["## Question 8\n","\n","Write a Python function named `predict()` that takes in the data about new students in a dictionary, and returns the predictions from the `model.pkl` object that was recently saved.\n","\n","On the example below, it should return something like:\n","```\n","{'predictions': [84.76219999999998]}\n","```\n","\n","* First, read in the `model.pkl` file into a new python variable named \"model\". \n","* Next, convert the input dictionary into a Pandas DataFrame using `pd.DataFrame()`.\n","* Then, run the `.predict()` function on the DataFrame to get an array with the prediction. Use the `.tolist()` method of the array to convert it into a list.\n","* Return the list in a dictionary with the key as `'predictions'`."]},{"cell_type":"markdown","metadata":{"id":"ehv1DJkkkBvD"},"source":["### Answer"]},{"cell_type":"code","execution_count":359,"metadata":{"id":"ZdzpCVqTkCA5","executionInfo":{"status":"ok","timestamp":1675548130195,"user_tz":360,"elapsed":5,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["new_students = [{\n","    'took4061_0' : 1,\n","    'took4061_1' : 0,\n","    'pythonExp_0' : 1,\n","    'pythonExp_1' : 0,\n","    'pythonExp_2' : 0,\n","    'statsRating_0' : 0,\n","    'statsRating_1' : 0,\n","    'statsRating_2' : 0,\n","    'statsRating_3' : 1,\n","    'statsRating_4' : 0,\n","    'statsRating_5' : 0,\n","    'gpa' : 3.1,\n","    'labHours' : 2.2,\n","    'studyHours' : 4.7\n","}]"]},{"cell_type":"code","execution_count":360,"metadata":{"id":"wenokS5mvK_s","executionInfo":{"status":"ok","timestamp":1675548130195,"user_tz":360,"elapsed":5,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":["def predict(new_students: dict) -> dict:\n","    # Read in the model\n","    with open('model.pkl', 'rb') as f:\n","        model = pickle.load(f)\n","    \n","    # Convert the input dictionary into a pandas DataFrame\n","    X_new = pd.DataFrame(new_students)\n","    \n","    # Ensure that the feature names are in the same order as they were in the training data\n","    X_new = X_new[['took4061_0', 'took4061_1', 'pythonExp_0', 'pythonExp_1', 'pythonExp_2', 'statsRating_0',\n","                   'statsRating_1', 'statsRating_2', 'statsRating_3', 'statsRating_4', 'statsRating_5',\n","                   'gpa', 'labHours', 'studyHours']]\n","    \n","    # Get predictions from the model\n","    predictions = model.predict(X_new).tolist()\n","    \n","    # Return the predictions in a dictionary with the key 'predictions'\n","    return {'predictions': predictions}"]},{"cell_type":"code","execution_count":361,"metadata":{"id":"GsqqH9zZtuHn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675548130196,"user_tz":360,"elapsed":6,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}},"outputId":"f614f778-287f-4346-80f3-dee5b05398be"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'predictions': [84.77680000000004]}\n"]}],"source":["print(predict(new_students))"]},{"cell_type":"markdown","metadata":{"id":"M0fDXHp2XCA6"},"source":["# End"]},{"cell_type":"code","execution_count":361,"metadata":{"id":"tld7F8rrT5yZ","executionInfo":{"status":"ok","timestamp":1675548130196,"user_tz":360,"elapsed":4,"user":{"displayName":"Leng Her","userId":"02260458738800442407"}}},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}